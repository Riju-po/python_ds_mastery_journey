{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95b8efb4-ef3e-498d-97a9-c945f7c1c308",
   "metadata": {},
   "source": [
    "## Module 5.3: Supervised Learning – Classification Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f0dbe04-09a4-4e33-9671-a1a4c884d5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete. Data is loaded and split.\n",
      "Target classes: ['malignant' 'benign']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>10.32</td>\n",
       "      <td>16.35</td>\n",
       "      <td>65.31</td>\n",
       "      <td>324.9</td>\n",
       "      <td>0.09434</td>\n",
       "      <td>0.04994</td>\n",
       "      <td>0.01012</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>0.06201</td>\n",
       "      <td>...</td>\n",
       "      <td>11.25</td>\n",
       "      <td>21.77</td>\n",
       "      <td>71.12</td>\n",
       "      <td>384.9</td>\n",
       "      <td>0.1285</td>\n",
       "      <td>0.08842</td>\n",
       "      <td>0.04384</td>\n",
       "      <td>0.02381</td>\n",
       "      <td>0.2681</td>\n",
       "      <td>0.07399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>20.18</td>\n",
       "      <td>19.54</td>\n",
       "      <td>133.80</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.11330</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.21330</td>\n",
       "      <td>0.125900</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>0.06053</td>\n",
       "      <td>...</td>\n",
       "      <td>22.03</td>\n",
       "      <td>25.07</td>\n",
       "      <td>146.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.1665</td>\n",
       "      <td>0.29420</td>\n",
       "      <td>0.53080</td>\n",
       "      <td>0.21730</td>\n",
       "      <td>0.3032</td>\n",
       "      <td>0.08075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>10.66</td>\n",
       "      <td>15.15</td>\n",
       "      <td>67.49</td>\n",
       "      <td>349.6</td>\n",
       "      <td>0.08792</td>\n",
       "      <td>0.04302</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1928</td>\n",
       "      <td>0.05975</td>\n",
       "      <td>...</td>\n",
       "      <td>11.54</td>\n",
       "      <td>19.20</td>\n",
       "      <td>73.20</td>\n",
       "      <td>408.3</td>\n",
       "      <td>0.1076</td>\n",
       "      <td>0.06791</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2710</td>\n",
       "      <td>0.06164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>13.56</td>\n",
       "      <td>13.90</td>\n",
       "      <td>88.59</td>\n",
       "      <td>561.3</td>\n",
       "      <td>0.10510</td>\n",
       "      <td>0.11920</td>\n",
       "      <td>0.07860</td>\n",
       "      <td>0.044510</td>\n",
       "      <td>0.1962</td>\n",
       "      <td>0.06303</td>\n",
       "      <td>...</td>\n",
       "      <td>14.98</td>\n",
       "      <td>17.13</td>\n",
       "      <td>101.10</td>\n",
       "      <td>686.6</td>\n",
       "      <td>0.1376</td>\n",
       "      <td>0.26980</td>\n",
       "      <td>0.25770</td>\n",
       "      <td>0.09090</td>\n",
       "      <td>0.3065</td>\n",
       "      <td>0.08177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>11.37</td>\n",
       "      <td>18.89</td>\n",
       "      <td>72.17</td>\n",
       "      <td>396.0</td>\n",
       "      <td>0.08713</td>\n",
       "      <td>0.05008</td>\n",
       "      <td>0.02399</td>\n",
       "      <td>0.021730</td>\n",
       "      <td>0.2013</td>\n",
       "      <td>0.05955</td>\n",
       "      <td>...</td>\n",
       "      <td>12.36</td>\n",
       "      <td>26.14</td>\n",
       "      <td>79.29</td>\n",
       "      <td>459.3</td>\n",
       "      <td>0.1118</td>\n",
       "      <td>0.09708</td>\n",
       "      <td>0.07529</td>\n",
       "      <td>0.06203</td>\n",
       "      <td>0.3267</td>\n",
       "      <td>0.06994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "546        10.32         16.35           65.31      324.9          0.09434   \n",
       "432        20.18         19.54          133.80     1250.0          0.11330   \n",
       "174        10.66         15.15           67.49      349.6          0.08792   \n",
       "221        13.56         13.90           88.59      561.3          0.10510   \n",
       "289        11.37         18.89           72.17      396.0          0.08713   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "546           0.04994         0.01012             0.005495         0.1885   \n",
       "432           0.14890         0.21330             0.125900         0.1724   \n",
       "174           0.04302         0.00000             0.000000         0.1928   \n",
       "221           0.11920         0.07860             0.044510         0.1962   \n",
       "289           0.05008         0.02399             0.021730         0.2013   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "546                 0.06201  ...         11.25          21.77   \n",
       "432                 0.06053  ...         22.03          25.07   \n",
       "174                 0.05975  ...         11.54          19.20   \n",
       "221                 0.06303  ...         14.98          17.13   \n",
       "289                 0.05955  ...         12.36          26.14   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "546            71.12       384.9            0.1285            0.08842   \n",
       "432           146.00      1479.0            0.1665            0.29420   \n",
       "174            73.20       408.3            0.1076            0.06791   \n",
       "221           101.10       686.6            0.1376            0.26980   \n",
       "289            79.29       459.3            0.1118            0.09708   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "546          0.04384               0.02381          0.2681   \n",
       "432          0.53080               0.21730          0.3032   \n",
       "174          0.00000               0.00000          0.2710   \n",
       "221          0.25770               0.09090          0.3065   \n",
       "289          0.07529               0.06203          0.3267   \n",
       "\n",
       "     worst fractal dimension  \n",
       "546                  0.07399  \n",
       "432                  0.08075  \n",
       "174                  0.06164  \n",
       "221                  0.08177  \n",
       "289                  0.06994  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plot style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Load the dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# Create DataFrame and Target Series\n",
    "X = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "y = pd.Series(cancer.target, name=\"target\") # target: 0 = malignant, 1 = benign\n",
    "\n",
    "# --- Initial Data Prep ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# We will use a pipeline for preprocessing for all models that need it\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import common metrics (we will explore these more in the next module)\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Helper dictionary to store results\n",
    "results = {}\n",
    "\n",
    "print(\"Setup Complete. Data is loaded and split.\")\n",
    "print(f\"Target classes: {cancer.target_names}\")\n",
    "display(X_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aedd02-c48a-407d-9e76-4a7d35963150",
   "metadata": {},
   "source": [
    "## 📌 Topic 1: Logistic Regression\n",
    "\n",
    "Despite its name, **Logistic Regression** is a **classification algorithm**. It models the **probability** that a given input point belongs to a certain class.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔑 A. Key Concepts\n",
    "\n",
    "#### 1. 📈 Sigmoid Function\n",
    "- The **core** of Logistic Regression.\n",
    "- Transforms any real-valued number into a value between **0 and 1**.\n",
    "- Output can be interpreted as a **probability**.\n",
    "- Formula:  \n",
    "  \\[\n",
    "  \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "  \\]\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. 🚧 Decision Boundary\n",
    "- The model learns a **boundary** (line, plane, or hyperplane) to **separate the classes**.\n",
    "- If a data point's predicted probability > 0.5 → **Class 1**; else → **Class 0**.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. ⚖️ Log-Loss (Binary Cross-Entropy)\n",
    "- The **cost function** Logistic Regression minimizes.\n",
    "- Penalizes the model for being **confident and wrong**.\n",
    "- Formula:  \n",
    "  \\[\n",
    "  \\text{LogLoss} = -\\left[ y \\log(p) + (1 - y) \\log(1 - p) \\right]\n",
    "  \\]\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. 📊 Interpreting Coefficients (Log-Odds)\n",
    "- The coefficients (**`model.coef_`**) represent the **change in log-odds** for a 1-unit increase in a feature.\n",
    "- **Positive coefficient** → increases the **log-odds** (and probability) of being **Class 1**.\n",
    "- **Negative coefficient** → decreases the log-odds.\n",
    "\n",
    "---\n",
    "\n",
    "> ✅ Logistic Regression is simple, interpretable, and effective for linearly separable problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49b51495-2e0f-4278-b76c-90af9da3aabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logistic Regression ---\n",
      "Accuracy: 0.9825\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.98      0.98        42\n",
      "      benign       0.99      0.99      0.99        72\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.98      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression is sensitive to feature scaling, so we use a pipeline.\n",
    "log_reg_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('log_reg', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the pipeline\n",
    "log_reg_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = log_reg_pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results['Logistic Regression'] = accuracy\n",
    "print(\"--- Logistic Regression ---\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=cancer.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6670670c-cb79-490d-80e7-923d920cd00f",
   "metadata": {},
   "source": [
    "## 📌 Topic 2: K-Nearest Neighbors (KNN)\n",
    "\n",
    "**K-Nearest Neighbors (KNN)** is a **simple**, **intuitive**, and **instance-based** learning algorithm. Unlike other models, KNN doesn’t build an explicit model — it memorizes the training data and makes predictions based on proximity.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔑 A. Key Concepts\n",
    "\n",
    "#### 1. 🧠 How It Works\n",
    "- For a new data point, KNN:\n",
    "  1. Identifies the **'K' nearest neighbors** from the training data.\n",
    "  2. Takes a **majority vote** for classification (or average for regression).\n",
    "- The prediction is based entirely on the labels of these nearby points.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. 📏 Distance Metrics\n",
    "- KNN uses distance to measure **closeness** between points.\n",
    "- Most common: **Euclidean Distance**.\n",
    "- Other options:\n",
    "  - **Manhattan Distance**\n",
    "  - **Minkowski Distance**\n",
    "  - **Cosine Similarity** (in some contexts)\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. ⚠️ Curse of Dimensionality\n",
    "- In **high-dimensional spaces**, distance becomes less meaningful.\n",
    "- All points tend to look equally far apart → **reduced model effectiveness**.\n",
    "- KNN performs best with a **limited number of relevant features**.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. ⚖️ Importance of Feature Scaling\n",
    "- KNN is **sensitive to scale** since it relies on distance.\n",
    "- Features like **salary (e.g., 0–100,000)** will dominate features like **age (e.g., 0–100)**.\n",
    "- Use scaling techniques:\n",
    "  - **StandardScaler** (mean = 0, std = 1)\n",
    "  - **MinMaxScaler** (scales to [0,1])\n",
    "\n",
    "---\n",
    "\n",
    "> ✅ KNN is great for small datasets and interpretable tasks, but it becomes inefficient on large datasets and sensitive to irrelevant features without preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23865275-50fd-440b-8bdb-63fdab28d2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- K-Nearest Neighbors ---\n",
      "Accuracy: 0.9561\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.95      0.93      0.94        42\n",
      "      benign       0.96      0.97      0.97        72\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5)) # K=5 is a common starting point\n",
    "])\n",
    "\n",
    "knn_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn_pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results['KNN (K=5)'] = accuracy\n",
    "print(\"\\n--- K-Nearest Neighbors ---\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=cancer.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0dff0d-7d73-405e-97cb-632468c30633",
   "metadata": {},
   "source": [
    "## 📌 Topic 3: Support Vector Machines (SVMs)\n",
    "\n",
    "**Support Vector Machines (SVMs)** are **powerful and versatile** classification models. Their core idea is to find the **optimal hyperplane** that best separates the classes in the feature space.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔑 A. Key Concepts\n",
    "\n",
    "#### 1. 📏 Maximal Margin Classifier\n",
    "- SVM seeks the **hyperplane** with the **maximum margin** — the widest possible separation between the classes.\n",
    "- This margin helps generalize better on unseen data by avoiding overly tight decision boundaries.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. 🎯 Support Vectors\n",
    "- **Support Vectors** are the **data points closest to the decision boundary**.\n",
    "- They are **critical** — moving them **will shift the hyperplane**.\n",
    "- The model is entirely defined by these points, not the rest of the data.\n",
    "\n",
    "---\n",
    "\n",
    "### ✨ The Kernel Trick (\"Amaze Factor\")\n",
    "\n",
    "#### ❓ What if data isn't linearly separable?\n",
    "- A straight line (or hyperplane) won't work in complex datasets.\n",
    "\n",
    "#### 💡 The Solution: **The Kernel Trick**\n",
    "- Instead of manually projecting data into higher dimensions (which is computationally expensive), SVM uses **kernels**.\n",
    "- Kernels implicitly map data to higher-dimensional spaces, where a linear separation **is possible**.\n",
    "\n",
    "---\n",
    "\n",
    "#### ⚙️ Common Kernels\n",
    "\n",
    "| Kernel     | Use Case                                          |\n",
    "|------------|---------------------------------------------------|\n",
    "| `'linear'` | For **linearly separable** datasets.              |\n",
    "| `'poly'`   | **Polynomial kernel** for capturing curved trends.|\n",
    "| `'rbf'`    | **Radial Basis Function** — default, **very powerful**. Can capture highly **non-linear boundaries**. |\n",
    "\n",
    "---\n",
    "\n",
    "> ✅ SVMs are especially effective in high-dimensional spaces and are memory-efficient because they only depend on support vectors.\n",
    "\n",
    "### 🧠 Interpreting SVM Kernel Choices\n",
    "\n",
    "Understanding how different kernels perform helps in selecting the right SVM configuration for your dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. 📈 Linear Kernel\n",
    "- **Assumes data is linearly separable**.\n",
    "- **Fast and efficient**, especially for:\n",
    "  - **High-dimensional data** (e.g., text classification).\n",
    "  - Cases where **features > samples**.\n",
    "- ✅ In our case: The **linear kernel performed very well**, suggesting the **breast cancer dataset** is **largely linearly separable**.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. 📉 Polynomial Kernel\n",
    "- Suitable for **curved, complex boundaries**.\n",
    "- Controlled by the **degree** parameter → higher degrees = more complex boundaries.\n",
    "- ⚠️ In our case: **Performed worse**.\n",
    "  - **Overfit** the data by creating a boundary that was **too complex**.\n",
    "  - Indicates the data did **not require** this level of flexibility.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. 🌐 RBF Kernel (Radial Basis Function)\n",
    "- The **default and most flexible** kernel.\n",
    "- Models **non-linear relationships** effectively.\n",
    "- ✅ In our case: **Performed the best**.\n",
    "  - Found a **slightly better non-linear boundary** than linear kernel.\n",
    "  - Avoided the **overfitting** seen with the polynomial kernel.\n",
    "- 🔑 **Best starting point** for most real-world problems.\n",
    "\n",
    "---\n",
    "\n",
    "> 📌 **Tip**: Try `rbf` first. Use `linear` when interpretability or speed matters. Use `poly` only when you suspect complex curvature and can regularize properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89162a19-aa3d-4031-b025-8f2e0bf618d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Support Vector Machine ---\n",
      "Accuracy: 0.9825\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.98      0.98        42\n",
      "      benign       0.99      0.99      0.99        72\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.98      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC # Support Vector Classifier\n",
    "\n",
    "# SVMs are very sensitive to feature scaling\n",
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(kernel='rbf', C=1.0, random_state=42)) # C is a regularization parameter\n",
    "])\n",
    "\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results['SVM (RBF Kernel)'] = accuracy\n",
    "print(\"\\n--- Support Vector Machine ---\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=cancer.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "130a230d-4eda-4fe0-806f-99d917ab4940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Comparing SVM Kernel Performance ---\n",
      "Accuracy with Linear Kernel: 0.9737\n",
      "Accuracy with Polynomial Kernel (degree=3): 0.9123\n",
      "Accuracy with RBF Kernel: 0.9825\n"
     ]
    }
   ],
   "source": [
    "# --- Comparing SVM Kernels ---\n",
    "# We'll create a pipeline for each kernel to see how they perform.\n",
    "# We already have the 'rbf' pipeline, let's create ones for 'linear' and 'poly'.\n",
    "\n",
    "print(\"\\n--- Comparing SVM Kernel Performance ---\")\n",
    "\n",
    "# 1. Linear Kernel\n",
    "svm_linear_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm_linear', SVC(kernel='linear', random_state=42))\n",
    "])\n",
    "svm_linear_pipeline.fit(X_train, y_train)\n",
    "y_pred_linear = svm_linear_pipeline.predict(X_test)\n",
    "accuracy_linear = accuracy_score(y_test, y_pred_linear)\n",
    "results['SVM (Linear Kernel)'] = accuracy_linear\n",
    "print(f\"Accuracy with Linear Kernel: {accuracy_linear:.4f}\")\n",
    "\n",
    "# 2. Polynomial Kernel\n",
    "# The 'degree' is a key hyperparameter for the polynomial kernel. Default is 3.\n",
    "svm_poly_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm_poly', SVC(kernel='poly', degree=3, random_state=42))\n",
    "])\n",
    "svm_poly_pipeline.fit(X_train, y_train)\n",
    "y_pred_poly = svm_poly_pipeline.predict(X_test)\n",
    "accuracy_poly = accuracy_score(y_test, y_pred_poly)\n",
    "results['SVM (Poly Kernel)'] = accuracy_poly\n",
    "print(f\"Accuracy with Polynomial Kernel (degree=3): {accuracy_poly:.4f}\")\n",
    "\n",
    "# 3. RBF Kernel (already done, just re-stating for comparison)\n",
    "print(f\"Accuracy with RBF Kernel: {results['SVM (RBF Kernel)']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c162f385-a506-456d-ad4e-449c0c6c2ca7",
   "metadata": {},
   "source": [
    "## 🌳 Topic 4: Decision Tree Classifiers\n",
    "\n",
    "**Decision Tree Classifiers** work similarly to Decision Tree Regressors, but are used for **classification tasks** instead of predicting continuous values.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔑 A. Key Concepts\n",
    "\n",
    "#### 1. 🔍 How It Works\n",
    "- The tree **partitions the data** by asking a series of **if/else questions** based on feature values.\n",
    "- Each split aims to create the most **homogeneous subsets** (pure class distributions) possible.\n",
    "- The process continues **recursively** until a stopping condition is met (e.g., max depth, minimum samples per leaf, or full purity).\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. 🌱 Impurity Measures\n",
    "- At each node, the algorithm chooses the **best feature and threshold** to split the data.\n",
    "- The goal: **maximize the purity** of the child nodes (i.e., minimize impurity).\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. 📉 Gini Impurity\n",
    "- Measures the **likelihood of incorrect classification** of a randomly chosen item.\n",
    "- A **Gini score of 0** → the node is **perfectly pure** (only one class present).\n",
    "- Formula:\n",
    "  \\[\n",
    "  \\text{Gini} = 1 - \\sum_{i=1}^{n} (p_i)^2\n",
    "  \\]\n",
    "  where \\( p_i \\) is the probability of class \\( i \\) at the node.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. 🔥 Entropy\n",
    "- Measures the **amount of disorder or impurity**.\n",
    "- Like Gini, **entropy = 0** means perfect purity.\n",
    "- Formula:\n",
    "  \\[\n",
    "  \\text{Entropy} = - \\sum_{i=1}^{n} p_i \\log_2(p_i)\n",
    "  \\]\n",
    "- It’s derived from **information theory** and represents how much information is needed to describe the class distribution.\n",
    "\n",
    "---\n",
    "\n",
    "> ✅ Both **Gini Impurity** and **Entropy** work similarly in practice. Gini is slightly faster, while Entropy can offer better performance in some cases depending on the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7eb1dd7-b3f7-4ac2-be55-882e3285506b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Decision Tree Classifier ---\n",
      "Accuracy: 0.9123\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.85      0.93      0.89        42\n",
      "      benign       0.96      0.90      0.93        72\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.90      0.92      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Decision Trees do not require feature scaling\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = tree_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results['Decision Tree'] = accuracy\n",
    "print(\"\\n--- Decision Tree Classifier ---\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=cancer.target_names))\n",
    "# Note: A single decision tree is often prone to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282d3fe-84fa-47bc-80c3-ef95418efdac",
   "metadata": {},
   "source": [
    "## 📌 Topic 5: Naive Bayes Classifiers\n",
    "\n",
    "**Naive Bayes** is a **simple yet powerful** probabilistic classifier that applies **Bayes' Theorem** with a strong (naive) assumption of feature independence. It’s especially effective for **text classification** tasks like spam filtering.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔑 A. Key Concepts\n",
    "\n",
    "#### 1. 📚 Bayes' Theorem\n",
    "- Computes the **posterior probability** of a class given the input features:\n",
    "  \\[\n",
    "  P(\\text{Class} | \\text{Features}) = \\frac{P(\\text{Features} | \\text{Class}) \\cdot P(\\text{Class})}{P(\\text{Features})}\n",
    "  \\]\n",
    "- Combines:\n",
    "  - **Likelihood**: \\( P(\\text{Features} | \\text{Class}) \\)\n",
    "  - **Prior**: \\( P(\\text{Class}) \\)\n",
    "  - **Evidence**: \\( P(\\text{Features}) \\)\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. 🧠 The \"Naive\" Assumption (\"Amaze Factor\")\n",
    "- Assumes all features are **conditionally independent** given the class.\n",
    "- In practice, this assumption is **rarely true**, but the algorithm still performs **surprisingly well**.\n",
    "\n",
    "#### 🔍 Example:\n",
    "- In a **spam filter**, Naive Bayes assumes:\n",
    "  - The probability of the word **\"viagra\"** appearing is **independent** of the word **\"sale\"**, **given** the email is spam.\n",
    "- Despite the unrealistic assumption, it works effectively in domains like **text classification**.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 Types of Naive Bayes Classifiers\n",
    "\n",
    "| Type            | Description                                                                 |\n",
    "|-----------------|-----------------------------------------------------------------------------|\n",
    "| **GaussianNB**  | Assumes features follow a **normal distribution**.<br> Best for **continuous** numeric data. |\n",
    "| **MultinomialNB** | Designed for **discrete counts**, like **word frequencies** in text documents. Ideal for **text classification**. |\n",
    "\n",
    "---\n",
    "\n",
    "> ✅ Naive Bayes is extremely **fast**, requires **very little training data**, and often serves as a strong **baseline model**, especially in **NLP tasks**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2bff4c8-926e-4484-b438-7bc1cdcacce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Gaussian Naive Bayes ---\n",
      "Accuracy: 0.9298\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.90      0.90      0.90        42\n",
      "      benign       0.94      0.94      0.94        72\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.92      0.92      0.92       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# We'll use a pipeline to scale data, which can sometimes help GaussianNB\n",
    "nb_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('nb', GaussianNB())\n",
    "])\n",
    "\n",
    "nb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb_pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results['Gaussian Naive Bayes'] = accuracy\n",
    "print(\"\\n--- Gaussian Naive Bayes ---\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=cancer.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a6d333-5ece-4c59-ba42-fa7d5abc583c",
   "metadata": {},
   "source": [
    "## 🤖 Topic 6: Ensemble Methods for Classification\n",
    "\n",
    "**Ensemble Methods** combine the predictions of multiple models to produce **better and more robust** results. Just like in regression, they help **reduce overfitting**, **increase accuracy**, and **improve generalization**.\n",
    "\n",
    "---\n",
    "\n",
    "### 🅰️ Random Forest Classifier\n",
    "\n",
    "#### 🌲 How It Works:\n",
    "- Builds **many Decision Trees**, each trained on a **random subset** of the data and features (bagging).\n",
    "- Final prediction is based on a **majority vote** from all trees.\n",
    "- Helps to **reduce overfitting** and improves stability compared to a single decision tree.\n",
    "\n",
    "> ✅ Great default classifier; works well with little tuning.\n",
    "\n",
    "---\n",
    "\n",
    "### 🅱️ Gradient Boosting Classifiers  \n",
    "(Examples: **XGBoost**, **LightGBM**, **CatBoost**)\n",
    "\n",
    "#### 🚀 How It Works:\n",
    "- Builds trees **sequentially**.\n",
    "- Each new tree tries to **correct the errors** made by the previous trees.\n",
    "- This leads to a **strong predictive model** from weak learners.\n",
    "- Often **outperforms** other models in structured data tasks.\n",
    "\n",
    "> ⚠️ Powerful but can overfit if not tuned carefully.\n",
    "\n",
    "---\n",
    "\n",
    "### 🆎 Voting Classifier\n",
    "\n",
    "#### 🗳️ How It Works:\n",
    "- Combines **multiple different models** (e.g., Logistic Regression, KNN, SVM).\n",
    "- Makes predictions based on a **majority vote** (for classification).\n",
    "- Can use:\n",
    "  - **Hard voting** (majority class)\n",
    "  - **Soft voting** (averaged probabilities)\n",
    "\n",
    "> ✅ Simple yet effective — useful when you have multiple models that perform well individually.\n",
    "\n",
    "---\n",
    "\n",
    "> 📌 Ensemble methods harness the strengths of multiple models, improving overall prediction accuracy and robustness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5155eca5-1b58-4c46-9c8e-9c934fd92593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Random Forest Classifier ---\n",
      "Accuracy: 0.9561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Python for Data science\\python_ds_mastery_journey\\module_0_setup\\venv_ds\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:44:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- XGBoost Classifier ---\n",
      "Accuracy: 0.9561\n",
      "\n",
      "--- CatBoost Classifier ---\n",
      "Accuracy: 0.9561\n",
      "\n",
      "--- Voting Classifier ---\n",
      "Accuracy: 0.9825\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "# --- Random Forest ---\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results['Random Forest'] = accuracy\n",
    "print(\"\\n--- Random Forest Classifier ---\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# --- XGBoost ---\n",
    "xgb_clf = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results['XGBoost'] = accuracy\n",
    "print(\"\\n--- XGBoost Classifier ---\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# --- CatBoost Classifier ---\n",
    "# As before, CatBoost can handle raw data, but for this comparison,\n",
    "# we'll fit it on the non-scaled data just like the other tree-based models.\n",
    "cat_clf = cb.CatBoostClassifier(random_state=42, verbose=0)\n",
    "cat_clf.fit(X_train, y_train)\n",
    "y_pred = cat_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results['CatBoost'] = accuracy\n",
    "print(\"\\n--- CatBoost Classifier ---\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# --- Voting Classifier ---\n",
    "# Let's combine three of our best models: Logistic Regression, SVM, and Random Forest\n",
    "# We use the pipeline for LogReg and the trained RF classifier\n",
    "clf1 = log_reg_pipeline\n",
    "clf2 = svm_pipeline\n",
    "clf3 = rf_clf\n",
    "# 'hard' voting uses majority vote. 'soft' voting averages probabilities.\n",
    "voting_clf = VotingClassifier(estimators=[('lr', clf1), ('svm', clf2), ('rf', clf3)], voting='hard')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results['Voting Classifier'] = accuracy\n",
    "print(\"\\n--- Voting Classifier ---\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06097309-f031-4581-a6ff-63a5e347dfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.982456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM (RBF Kernel)</td>\n",
       "      <td>0.982456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Voting Classifier</td>\n",
       "      <td>0.982456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM (Linear Kernel)</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN (K=5)</td>\n",
       "      <td>0.956140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.956140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.956140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.956140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.929825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.912281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM (Poly Kernel)</td>\n",
       "      <td>0.912281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  Accuracy\n",
       "0    Logistic Regression  0.982456\n",
       "2       SVM (RBF Kernel)  0.982456\n",
       "10     Voting Classifier  0.982456\n",
       "3    SVM (Linear Kernel)  0.973684\n",
       "1              KNN (K=5)  0.956140\n",
       "7          Random Forest  0.956140\n",
       "8                XGBoost  0.956140\n",
       "9               CatBoost  0.956140\n",
       "6   Gaussian Naive Bayes  0.929825\n",
       "5          Decision Tree  0.912281\n",
       "4      SVM (Poly Kernel)  0.912281"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df= pd.DataFrame(list(results.items()), columns=['Model', 'Accuracy'])\n",
    "results_df.sort_values(by='Accuracy', ascending=False, inplace=True)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01b4aa3-bec6-4027-8db4-fdfe454bd768",
   "metadata": {},
   "source": [
    "## Mini-Project: Customer Churn Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac8693fd-3af7-4472-903f-1c897adaf8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'telco_churn.csv' file created successfully.\n",
      "You can now proceed with the mini-project.\n"
     ]
    }
   ],
   "source": [
    "# This code block will download the dataset and create the CSV file.\n",
    "# Run this cell once.\n",
    "\n",
    "# URL to the raw CSV data from a reliable source\n",
    "url = \"https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv\"\n",
    "\n",
    "try:\n",
    "    # Read the data from the URL into a pandas DataFrame\n",
    "    df_to_save = pd.read_csv(url)\n",
    "    \n",
    "    # Save the DataFrame to a local CSV file\n",
    "    df_to_save.to_csv(\"telco_churn.csv\", index=False)\n",
    "    \n",
    "    print(\"'telco_churn.csv' file created successfully.\")\n",
    "    print(\"You can now proceed with the mini-project.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while trying to download the data: {e}\")\n",
    "    print(\"Please check your internet connection or use the manual copy/paste method if the issue persists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b28b21-9816-4fe8-ad8f-71e20d5597f0",
   "metadata": {},
   "source": [
    "### Goal: Apply the classification models you've learned to predict whether a customer will churn (leave the service).\n",
    "- Dataset: telco_churn.csv (which you have now successfully loaded).\n",
    "1. **Load and Prepare Data:**\n",
    "    - Load the telco_churn.csv dataset.\n",
    "    - The TotalCharges column has spaces for new customers who haven't been charged yet. Convert it to a numeric type. This will create some missing values. (Hint: `pd.to_numeric(df['TotalCharges'], errors='coerce')`).\n",
    "    - Fill any missing TotalCharges values (e.g., with the median or 0).\n",
    "    - The Churn column is your target y. Convert its 'Yes'/'No' values to 1s and 0s. (Hint: use `.map({'No': 0, 'Yes': 1})`).\n",
    "    - Your features X will be all other columns except customerID (which is just an identifier) and Churn.\n",
    "2. **Train-Test Split:** Split your X and y data into training and testing sets. Use `test_size=0.2` and `random_state=42`. Use `stratify=y` to ensure the proportion of churners is the same in both sets.\n",
    "3. **Create a Preprocessing Pipeline:**\n",
    "    - First, identify which of your feature columns are numerical and which are categorical.\n",
    "    - Create a ColumnTransformer that applies different preprocessing steps to different types of columns.\n",
    "        - **For numerical features:** Use a Pipeline that first fills any remaining missing values (SimpleImputer(strategy='median')) and then scales the data (StandardScaler).\n",
    "        - **For categorical features:** Use a Pipeline that first fills any remaining missing values (SimpleImputer(`strategy='most_frequent'`)) and then one-hot encodes the data (OneHotEncoder(`handle_unknown='ignore'`)).\n",
    "4. **Apply and Compare Models:**\n",
    "    - Create full, end-to-end Pipeline objects for at least four different classifiers (e.g., Logistic Regression, SVM, Random Forest, XGBoost, CatBoost). Each pipeline will have your ColumnTransformer from step 3 as its first step and the classifier as its second step.\n",
    "    - Fit each of these full pipelines on the raw X_train and y_train data.\n",
    "    - For each pipeline, make predictions on X_test and evaluate its performance. Store the results.\n",
    "5. **Summarize and Interpret:**\n",
    "    - Create a summary table (e.g., a Pandas DataFrame) showing the Accuracy, Precision (for class 1), and Recall (for class 1) of each model.\n",
    "    - Identify the best-performing model based on your chosen metrics.\n",
    "    - In a Markdown cell, answer this critical business question: For a customer churn problem, why might a company care more about maximizing Recall for the 'Yes' (churn) class than maximizing overall Accuracy? What is the business trade-off? (This is a key \"amaze factor\" question)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5253722a-702f-47ef-9770-334b5f57c156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier # New import\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Set plot style\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b002971c-336d-4d9b-813f-81d1f54a1cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "telco= pd.read_csv('telco_churn.csv')\n",
    "# Copying the data\n",
    "df=telco.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a24881-1fb0-484f-9921-4bf1c5f5c797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
       "0           Electronic check          29.85         29.85    No  \n",
       "1               Mailed check          56.95        1889.5    No  \n",
       "2               Mailed check          53.85        108.15   Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
       "4           Electronic check          70.70        151.65   Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bd9c124-00b6-48bc-9b2a-a550444e8d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   gender            7043 non-null   object \n",
      " 2   SeniorCitizen     7043 non-null   int64  \n",
      " 3   Partner           7043 non-null   object \n",
      " 4   Dependents        7043 non-null   object \n",
      " 5   tenure            7043 non-null   int64  \n",
      " 6   PhoneService      7043 non-null   object \n",
      " 7   MultipleLines     7043 non-null   object \n",
      " 8   InternetService   7043 non-null   object \n",
      " 9   OnlineSecurity    7043 non-null   object \n",
      " 10  OnlineBackup      7043 non-null   object \n",
      " 11  DeviceProtection  7043 non-null   object \n",
      " 12  TechSupport       7043 non-null   object \n",
      " 13  StreamingTV       7043 non-null   object \n",
      " 14  StreamingMovies   7043 non-null   object \n",
      " 15  Contract          7043 non-null   object \n",
      " 16  PaperlessBilling  7043 non-null   object \n",
      " 17  PaymentMethod     7043 non-null   object \n",
      " 18  MonthlyCharges    7043 non-null   float64\n",
      " 19  TotalCharges      7032 non-null   float64\n",
      " 20  Churn             7043 non-null   object \n",
      "dtypes: float64(2), int64(2), object(17)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Converting TotalCharges column to numeric\n",
    "df['TotalCharges']= pd.to_numeric(df['TotalCharges'], errors= 'coerce')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f6e418b-ab8f-48f7-ba83-420e72803520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   gender            7043 non-null   object \n",
      " 2   SeniorCitizen     7043 non-null   int64  \n",
      " 3   Partner           7043 non-null   object \n",
      " 4   Dependents        7043 non-null   object \n",
      " 5   tenure            7043 non-null   int64  \n",
      " 6   PhoneService      7043 non-null   object \n",
      " 7   MultipleLines     7043 non-null   object \n",
      " 8   InternetService   7043 non-null   object \n",
      " 9   OnlineSecurity    7043 non-null   object \n",
      " 10  OnlineBackup      7043 non-null   object \n",
      " 11  DeviceProtection  7043 non-null   object \n",
      " 12  TechSupport       7043 non-null   object \n",
      " 13  StreamingTV       7043 non-null   object \n",
      " 14  StreamingMovies   7043 non-null   object \n",
      " 15  Contract          7043 non-null   object \n",
      " 16  PaperlessBilling  7043 non-null   object \n",
      " 17  PaymentMethod     7043 non-null   object \n",
      " 18  MonthlyCharges    7043 non-null   float64\n",
      " 19  TotalCharges      7043 non-null   float64\n",
      " 20  Churn             7043 non-null   object \n",
      "dtypes: float64(2), int64(2), object(17)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# filling missing values in TotalCharges column with median value.\n",
    "median_totalcharges= df['TotalCharges'].median()\n",
    "df['TotalCharges']= df['TotalCharges'].fillna(median_totalcharges,)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c56c4500-f53f-44c0-aeea-7ad371b4d053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7043.000000</td>\n",
       "      <td>7043.000000</td>\n",
       "      <td>7043.000000</td>\n",
       "      <td>7043.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.162147</td>\n",
       "      <td>32.371149</td>\n",
       "      <td>64.761692</td>\n",
       "      <td>2281.916928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.368612</td>\n",
       "      <td>24.559481</td>\n",
       "      <td>30.090047</td>\n",
       "      <td>2265.270398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>18.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>402.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>70.350000</td>\n",
       "      <td>1397.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>89.850000</td>\n",
       "      <td>3786.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>118.750000</td>\n",
       "      <td>8684.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SeniorCitizen       tenure  MonthlyCharges  TotalCharges\n",
       "count    7043.000000  7043.000000     7043.000000   7043.000000\n",
       "mean        0.162147    32.371149       64.761692   2281.916928\n",
       "std         0.368612    24.559481       30.090047   2265.270398\n",
       "min         0.000000     0.000000       18.250000     18.800000\n",
       "25%         0.000000     9.000000       35.500000    402.225000\n",
       "50%         0.000000    29.000000       70.350000   1397.475000\n",
       "75%         0.000000    55.000000       89.850000   3786.600000\n",
       "max         1.000000    72.000000      118.750000   8684.800000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69f2167a-8418-4b71-b51c-177b912a851b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "0    5174\n",
       "1    1869\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting Churn column's 'Yes'/'No' values to 1s and 0s\n",
    "df['Churn'] = df['Churn'].map({'No': 0, 'Yes': 1})\n",
    "df['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f8c0dbc-f086-46c5-97b5-4a4194471666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  Female              0     Yes         No       1           No   \n",
       "1    Male              0      No         No      34          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity OnlineBackup  \\\n",
       "0  No phone service             DSL             No          Yes   \n",
       "1                No             DSL            Yes           No   \n",
       "\n",
       "  DeviceProtection TechSupport StreamingTV StreamingMovies        Contract  \\\n",
       "0               No          No          No              No  Month-to-month   \n",
       "1              Yes          No          No              No        One year   \n",
       "\n",
       "  PaperlessBilling     PaymentMethod  MonthlyCharges  TotalCharges  \n",
       "0              Yes  Electronic check           29.85         29.85  \n",
       "1               No      Mailed check           56.95       1889.50  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= df.drop(columns=['customerID', 'Churn'])\n",
    "y = df['Churn']\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68718149-1a36-463b-bbbf-876481377d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53b3670d-31ec-4ed4-bca8-9d1aeb0bc6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train set: (5634, 19)\n",
      "y_train set: (5634,)\n",
      "------------------------------\n",
      "X_test set: (1409, 19)\n",
      "y_test set: (1409,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting of the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state= 42, stratify=y)\n",
    "\n",
    "print(f\"X_train set: {X_train.shape}\")\n",
    "print(f\"y_train set: {y_train.shape}\")\n",
    "print(\"-\"*30)\n",
    "print(f\"X_test set: {X_test.shape}\")\n",
    "print(f\"y_test set: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18acf71a-4067-4447-b241-5e8760b50811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 4 numerical features.\n",
      "Identified 15 categorical features.\n",
      "Training LogisticRegression...\n",
      "LogisticRegression evaluation complete.\n",
      "\n",
      "Training Support Vector Machine...\n",
      "Support Vector Machine evaluation complete.\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest evaluation complete.\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Python for Data science\\python_ds_mastery_journey\\module_0_setup\\venv_ds\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:43:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost evaluation complete.\n",
      "\n",
      "Training CatBoost...\n",
      "CatBoost evaluation complete.\n",
      "\n",
      "---\n",
      "Training Voting Classifier...\n",
      "Voting Classifier evaluation complete.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.805536</td>\n",
       "      <td>0.657233</td>\n",
       "      <td>0.558824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.784954</td>\n",
       "      <td>0.605970</td>\n",
       "      <td>0.542781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>0.797019</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting Classifier</th>\n",
       "      <td>0.799858</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.524064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.791341</td>\n",
       "      <td>0.641844</td>\n",
       "      <td>0.483957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.777857</td>\n",
       "      <td>0.603390</td>\n",
       "      <td>0.475936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy  Precision    Recall\n",
       "LogisticRegression      0.805536   0.657233  0.558824\n",
       "XGBoost                 0.784954   0.605970  0.542781\n",
       "CatBoost                0.797019   0.642857  0.529412\n",
       "Voting Classifier       0.799858   0.653333  0.524064\n",
       "Support Vector Machine  0.791341   0.641844  0.483957\n",
       "Random Forest           0.777857   0.603390  0.475936"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Identify numerical and categorical columns\n",
    "numerical_features= X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features= X.select_dtypes(include=['object', 'bool', 'category']).columns.tolist()\n",
    "print(f\"Identified {len(numerical_features)} numerical features.\")\n",
    "print(f\"Identified {len(categorical_features)} categorical features.\")\n",
    "\n",
    "# Create a preprocessing pipeline for numerical features\n",
    "numeric_transformers = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy= 'median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "# Create a preprocessing pipeline for categorical features\n",
    "categorical_transformers = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown = 'ignore'))\n",
    "])\n",
    "\n",
    "# Creating a single ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers =[\n",
    "    ('num', numeric_transformers, numerical_features),\n",
    "    ('cat', categorical_transformers, categorical_features)\n",
    "])\n",
    "\n",
    "# Define the individual classifiers\n",
    "classifiers={\n",
    "    'LogisticRegression': LogisticRegression(random_state=42),\n",
    "    'Support Vector Machine': SVC(kernel = 'rbf', C=1.0, random_state= 42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "    'CatBoost': CatBoostClassifier(random_state=42, verbose=0)\n",
    "}\n",
    "\n",
    "# Store the results\n",
    "results ={}\n",
    "\n",
    "# Iterate through each individual classifier\n",
    "for name, clf in classifiers.items():\n",
    "    model_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "    print(f\"Training {name}...\")\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "    y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "    # Storing results\n",
    "    results[name] = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred, pos_label=1),\n",
    "        'Recall': recall_score(y_test, y_pred, pos_label=1)\n",
    "    }\n",
    "    print(f\"{name} evaluation complete.\\n\")\n",
    "    \n",
    "# Creating Voting Classifier\n",
    "print(\"---\")\n",
    "print(\"Training Voting Classifier...\")\n",
    "clf1 = LogisticRegression(random_state=42)\n",
    "clf2 = SVC(kernel = 'rbf', C=1.0, random_state= 42)\n",
    "clf3 = CatBoostClassifier(random_state=42, verbose=0)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('lr',clf1),\n",
    "    ('svm', clf2),\n",
    "    ('catboost', clf3)], voting='hard'\n",
    ")\n",
    "\n",
    "# Create a full pipeline for the Voting Classifier\n",
    "voting_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', voting_clf)\n",
    "])\n",
    "voting_pipeline.fit(X_train, y_train)\n",
    "y_pred_voting = voting_pipeline.predict(X_test)\n",
    "\n",
    "# Store voting results\n",
    "results['Voting Classifier'] = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_voting),\n",
    "    'Precision': precision_score(y_test, y_pred_voting, pos_label=1),\n",
    "    'Recall': recall_score(y_test, y_pred_voting, pos_label=1)\n",
    "}\n",
    "print(\"Voting Classifier evaluation complete.\\n\")\n",
    "\n",
    "# Create a pandas DataFrame from the results for a clean summary\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df.sort_values(by = 'Recall', ascending= False, inplace = True)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c28786a-6b0e-48ec-af5d-53833176a6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_5688\\98170134.py:3: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=results_df.index, y=results_df['Recall'], palette='viridis')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a bar chart for Recall scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=results_df.index, y=results_df['Recall'], palette='viridis')\n",
    "plt.title('Model Recall Comparison', fontsize=16)\n",
    "plt.xlabel('Model', fontsize=12)\n",
    "plt.ylabel('Recall Score', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2178ffd9-a7ef-48cf-9db1-04c21bc20470",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "**The best model is LogisticRegression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e90f31-afae-4da7-a164-0b5ab86b0f05",
   "metadata": {},
   "source": [
    "**Why Recall is More Important Than Accuracy in Customer Churn Prediction**\n",
    "\n",
    "For a customer churn problem, a company cares more about maximizing **Recall** than overall **Accuracy** because the cost of making different types of mistakes is vastly unequal.\n",
    "\n",
    "---\n",
    "\n",
    "**Why Accuracy Can Be Misleading**\n",
    "\n",
    "Accuracy can be dangerously misleading.  \n",
    "If only **5%** of your customers churn, a naive model that predicts **no one will churn** is **95% accurate**—but **completely useless** for business purposes.\n",
    "\n",
    "> It fails at its one job: identifying at-risk customers.\n",
    "\n",
    "---\n",
    "\n",
    "**Why Recall Matters Most**\n",
    "\n",
    "**Recall** answers the most critical business question:  \n",
    "> \"_Of all the customers who were actually going to leave, what percentage did we successfully flag?_\"\n",
    "\n",
    "- A **False Negative** (low Recall) is when your model predicts a customer will stay, but they actually **leave**.  \n",
    "  This is the most **expensive error**. You lose revenue **forever** because you never got the chance to intervene.\n",
    "\n",
    "- A **False Positive** is when your model predicts a customer will leave, but they were planning to stay.  \n",
    "  The cost is minimal—you may waste a small retention bonus on a loyal customer.\n",
    "\n",
    " **Maximizing Recall** is a direct strategy to **minimize the most costly error**: False Negatives.\n",
    "\n",
    "---\n",
    "\n",
    "**Business Trade-Off: Recall vs. Precision**\n",
    "\n",
    "While Recall is critical, it comes with a trade-off:\n",
    "\n",
    "- **Precision** answers:  \n",
    "  > \"_Of all the customers we predicted would churn, how many were we correct about?_\"\n",
    "\n",
    "- 🔁 **The Trade-off**:  \n",
    "  As you increase **Recall** to catch more potential churners, **Precision** may drop.  \n",
    "  This means more **False Positives**—happy customers receiving unnecessary retention offers.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**\n",
    "\n",
    "- Maximize **Recall** to reduce customer loss.\n",
    "- Monitor **Precision** to balance business costs.\n",
    "- Don't rely solely on **Accuracy**—it hides critical flaws in imbalance problems like churn.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
