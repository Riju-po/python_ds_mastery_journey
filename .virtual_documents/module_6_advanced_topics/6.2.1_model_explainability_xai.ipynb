


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import shap
import lime
import lime.lime_tabular

# --- Rebuild our best model from the previous module ---
# (Imports for all the sklearn components)
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE
from xgboost import XGBClassifier

# Load and prep data
df = pd.read_csv("https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv")
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
df.dropna(subset=['TotalCharges'], inplace=True)
df['Churn'] = df['Churn'].map({'No': 0, 'Yes': 1})
X = df.drop(columns=['customerID', 'Churn'])
y = df['Churn']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Rebuild the preprocessing pipeline
numerical_features = X_train.select_dtypes(include=np.number).columns.tolist()
categorical_features = X_train.select_dtypes(include='object').columns.tolist()
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numerical_features),
    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)
])

# Rebuild the final, best-performing XGBoost pipeline
# Using representative hyperparameters from the tuning process
best_params = {'classifier__subsample': 0.7, 'classifier__scale_pos_weight': 3, 
               'classifier__n_estimators': 100, 'classifier__max_depth': 3, 
               'classifier__learning_rate': 0.1, 'classifier__gamma': 0.5, 
               'classifier__colsample_bytree': 0.8}

final_model_pipeline = ImbPipeline(steps=[
    ('preprocessor', preprocessor),
    ('smote', SMOTE(random_state=42)),
    ('classifier', XGBClassifier(random_state=42, eval_metric='logloss', use_label_encoder=False))
])
final_model_pipeline.set_params(**best_params)

# Train the model
final_model_pipeline.fit(X_train, y_train)
print("Best performing model pipeline is trained and ready for explanation.")

# For XAI techniques, we need the processed data and feature names
# We fit the preprocessor on the full training data to get all feature names
preprocessor.fit(X_train)
X_train_processed = pd.DataFrame(preprocessor.transform(X_train), columns=preprocessor.get_feature_names_out())
X_test_processed = pd.DataFrame(preprocessor.transform(X_test), columns=preprocessor.get_feature_names_out())








# Extract the classifier and preprocessor steps from the pipeline
xgb_model = final_model_pipeline.named_steps['classifier']

importances = pd.Series(xgb_model.feature_importances_, index=preprocessor.get_feature_names_out())
sorted_importances = importances.sort_values(ascending=False).head(15)

plt.figure(figsize=(10, 8))
sns.barplot(x=sorted_importances.values, y=sorted_importances.index, palette='mako')
plt.title('Gini Feature Importances from XGBoost Model')
plt.xlabel('Importance Score')
plt.show()








from sklearn.inspection import permutation_importance

print("Calculating Permutation Importance...")
# We use the full pipeline and the original test data
perm_importance = permutation_importance(
    final_model_pipeline, X_test, y_test, 
    n_repeats=10, random_state=42, n_jobs=-1, scoring='recall'
)

# Create a DataFrame for visualization
sorted_idx = perm_importance.importances_mean.argsort()
perm_df = pd.DataFrame(perm_importance.importances[sorted_idx].T,
                       columns=X_test.columns[sorted_idx])

plt.figure(figsize=(12, 8))
perm_df.plot(kind='box', vert=False, whis=10)
plt.title('Permutation Importance (Measured by Decrease in Recall on Test Set)')
plt.axvline(x=0, color='k', linestyle='--')
plt.xlabel('Decrease in Recall Score')
plt.show()





from sklearn.inspection import PartialDependenceDisplay

# We can only plot a few at a time for readability
features_to_plot = ['tenure', 'MonthlyCharges']

print("\n--- Generating PDP and ICE Plots ---")
fig, ax = plt.subplots(figsize=(12, 5))
display = PartialDependenceDisplay.from_estimator(
    final_model_pipeline,
    X_test, # PDP should be calculated on a representative dataset
    features_to_plot,
    kind='both', # 'both' shows PDP and ICE
    n_jobs=-1,
    grid_resolution=20,
    ax=ax
)
fig.suptitle('Partial Dependence and ICE Plots')
plt.show()





# --- SHAP Implementation ---
# 1. Create an explainer object. For tree models, TreeExplainer is much faster.
# We need to explain the final model in the pipeline.
explainer = shap.TreeExplainer(final_model_pipeline.named_steps['classifier'])

# 2. Calculate SHAP values for the preprocessed test set
shap_values = explainer.shap_values(X_test_processed)

# 3. Global Explanation: SHAP Summary Plot (Beeswarm)
# This is often the most information-dense plot in all of XAI
print("\n--- SHAP Summary Plot ---")
shap.summary_plot(shap_values, X_test_processed, feature_names=preprocessor.get_feature_names_out())

# 4. Local Explanation: Force Plot for a single prediction
# Let's explain the first instance in the test set
print("\n--- SHAP Force Plot (Single Prediction) ---")
shap.initjs() # Initialize javascript for plotting
shap.force_plot(explainer.expected_value,
                shap_values[0,:],
                X_test_processed.iloc[0,:],
                matplotlib=True)





# --- LIME Implementation with Correct Fix ---

import lime.lime_tabular
from IPython.display import display, HTML

# 1. Create a LIME Explainer object
lime_explainer = lime.lime_tabular.LimeTabularExplainer(
    training_data=X_train_processed.values,
    feature_names=preprocessor.get_feature_names_out(),
    class_names=['No Churn', 'Churn'],
    mode='classification'
)

# 2. Explain a single instance (let's use the 5th instance from the test set)
instance_to_explain = X_test_processed.iloc[5, :]

# LIME needs a function that takes the perturbed data and returns prediction probabilities
lime_predict_fn = lambda x: final_model_pipeline.named_steps['classifier'].predict_proba(x)

lime_explanation = lime_explainer.explain_instance(
    instance_to_explain.values,
    lime_predict_fn,
    num_features=10  # Show the top 10 features
)

# 3. Show the explanation (HTML rendering)
print("\n--- LIME Explanation for a Single Prediction ---")
html_exp = lime_explanation.as_html()
display(HTML(html_exp))







